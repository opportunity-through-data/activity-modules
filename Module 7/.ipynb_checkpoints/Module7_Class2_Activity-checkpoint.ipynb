{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 7 Activity: Classification\n",
    "\n",
    "In this module, we will be focusing on a simple classification problem. We will be looking at [Kickstarter Data](https://www.kaggle.com/kemical/kickstarter-projects) and attempting to classify projects as successful or failed based on the different attributes of each project, such as the monetary goal, the number of backers, and how long the project was on Kickstarter.\n",
    "\n",
    "This is a problem of binary classification, where there are two possible outcomes - success or failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore our data a little bit. We'll load it in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = pd.read_csv('ks_2020.csv')\n",
    "print(ks.shape)\n",
    "ks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a classification model, we want to be able to test our model on data that it hasn't seen before. If we try to test it on a point that it already knows the answer for, it'll be correct 100% of the time! For this reason, we split up our data into a training set and a test set. The cell below accomplishes this - it sets aside 10% of the data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, test_size, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    data_size = len(data)\n",
    "    test_data_len = int(test_size * data_size)\n",
    "    train_data_len = data_size - test_data_len\n",
    "    test_indices = np.random.choice(np.arange(data_size), test_data_len, replace=False)\n",
    "    test = data.loc[test_indices]\n",
    "    train = data[~data.index.isin(test_indices)]\n",
    "    return train, test\n",
    "    \n",
    "train, test = train_test_split(ks, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this module, we'll be implementing a k-nearest neighbors classifier. The idea behind this type of classifier is to look at the k points closest to our point of interest, and classify our point as whatever category the majority of surrounding points are. For example, look at the image of the plot below. The green point has a single nearest neighbor, which is a Sycamore. Of its 5 closest neighbors, 3 are Birch. This would lead us to classify our green point as Birch if we were using KNN with k = 5. \n",
    "\n",
    "In our case, rather than classifying trees based on tree diameter and height, we're looking to see if we can classify kickstarter projects as successful or failed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a href=\"https://otd.gitbook.io/book/module-7/nearest-neighbors\"><img src=\"knn.PNG\"></a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eda\n",
    "samp = ks.sample(1000)\n",
    "for state in samp['state'].unique():\n",
    "    samp_state = samp[samp['state'] == state]\n",
    "    plt.scatter(samp_state['duration'], samp_state['backers'], label=state)\n",
    "plt.ylim(0, 1000)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-nearest neighbors (KNN) classification works on distances between points, so we'll create a function that tells us the distance between a set of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(features_array_1, features_array_2):\n",
    "    return np.mean(np.sqrt(np.sum((features_array_1 - features_array_2)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For KNN, we need to select numerical features in order to be able to calculate distances. Our data contain various numerical features, and we'll use all of them - these are `goal`, `backers`, `duration`, and `name_length`. We need to select the columns that contain these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train[['goal', 'backers', 'duration', 'name_length']]\n",
    "train_labels = train['state']\n",
    "test_features = test[['goal', 'backers', 'duration', 'name_length']]\n",
    "test_labels = test['state']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first Kickstarter project in our dataset, the 'KILLER GRANNY: based on our award-winning script', we'll compute the distance to the rest of the projects in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance between first and second projects\n",
    "train_features.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance(train_features.iloc[0], train_features.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to standardize these units, though! The distance between goals might be a lot larger than the distance between name lengths, so we can turn our data into \"standard units\" -- that is, we will subtract our data from the mean and divide by the standard deviation to get our data into units that make more sense for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_units(array):\n",
    "    m = np.mean(array)\n",
    "    sd = np.std(array)\n",
    "    return (array - m)/sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now apply our standard units function to all of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_features.apply(standard_units)\n",
    "test_features = test_features.apply(standard_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the distance between the first two train features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance(train_features.iloc[0], train_features.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And between the first test feature and the first train feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " distance(test_features.iloc[0], train_features.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Writing the Function\n",
    "Now, let's write a function to calculate the top \"k\" neighbors for each piece of test data. Fill in all the spaces with ellipses!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nn(train_features, train_labels, test_data, k):\n",
    "    feature_labels = []\n",
    "    feature_distances = []\n",
    "    for i in range(train_features.shape[0]):\n",
    "        train_i = ...\n",
    "        train_label = ...\n",
    "        feature_labels.append(...)\n",
    "        feature_distances.append(...)\n",
    "    \n",
    "    # This code is taking the labels for the k values that have the minimum distance!\n",
    "    k_indices = (np.array(feature_distances)).argsort()[:k]\n",
    "    k_labels = np.take(feature_labels, k_indices)\n",
    "    # k_labels is going to be an array of k values, all either \"failed\" or \"successful\"!\n",
    "    num_failed = np.count_nonzero(...)\n",
    "    num_successful = np.count_nonzero(...)\n",
    "    if num_failed >= num_successful:\n",
    "        return 'failed'\n",
    "    else:\n",
    "        return 'successful'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try classifying the first piece of test data using 3-nn; we'll use only the first 1000 pieces of data for speed (try running it on all the data later! how long does it take?):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_nn(train_features.iloc[0:1000], train_labels.iloc[0:1000], test_features.iloc[0], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2:\n",
    "Try running the 3-nearest neighbors classifier on 100 pieces of training data; how many did it get right? How many did it get wrong? (You might want to use only a subset of the training data, as above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct = 0\n",
    "for i in range(100):\n",
    "    test_data = ...\n",
    "    label = k_nn(...)\n",
    "    if label == test_labels.iloc[i]:\n",
    "        ...\n",
    "\n",
    "pct_correct = num_correct / 100\n",
    "pct_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3:\n",
    "What happens to the accuracy you change the value of k? Try it out on k = 1, 2, 4, and 5 using the following cells! You may want to copy some or most of your code from question 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
