{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 6: Pandas, Visualization\n",
    "### NBA Tweets Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this activity, we'll be using the material we've learned to explore a [dataset of tweets from the 2018 NBA finals between the Warriors and the Cavaliers](https://www.kaggle.com/xvivancos/tweets-during-cavaliers-vs-warriors)! This dataset is not what we call **clean**, which means that the data contains lots of imperfections! In order to make it easier to analyze, we first want to clean our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll load in our data. Note that we're providing two additional arguments to our `pd.read_csv` function: `encoding`, which specifies how to read the text, and `index_col`, which specifies which column to use as the index (kind of like column names, but for rows) of the dataset.\n",
    "\n",
    "Try running the two commented-out lines of code without the extra arguments to `pd.read_csv`, and see what happens! What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"TweetsNBA.csv\", encoding = \"ISO-8859-1\", index_col=0)\n",
    "# tweets = pd.read_csv(\"TweetsNBA.csv\", encoding = \"ISO-8859-1\")\n",
    "# tweets = pd.read_csv(\"TweetsNBA.csv\", index_col=0)\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how many tweets we have and what data we have about each tweet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you take a look at the dataset, you might notice that there are a lot of columns with values that just say `NaN`. `NaN` is shorthand for `Not a Number`, which is used to denote missing values!\n",
    "\n",
    "We can use a few methods to work with `NaN` values in Pandas.\n",
    "\n",
    "We can find the null values in a DataFrame (the whole table) or Series (a particular column or row) with the following commands:\n",
    "- `df.isna()` returns True for each null value and False for each non-null value\n",
    "- `df.notna()` returns False for each null value and True for each non-null value\n",
    "\n",
    "Once you know what null values exist, you can handle null values with the following functions:\n",
    "- [`fillna(<value>)`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html) will fill all null values with the value you pass in. We can fill null values with another value such as 'missing' or 0, or the mean of the data, or something else, depending on the data.\n",
    "- [`dropna()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html) will drop all rows or columns that have null values. You can choose to drop rows or columns by using the `index` argument; 0 means drop any rows with null values, and 1 means drop any columns that have null values. You can also specify whether to drop things based on how many null values there are with the `how` and `thresh` arguments, which you can read more about in the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html)\n",
    "\n",
    "First, let's try and write some code to figure out how many missing values there are in each column:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT\n",
    "for column in \"___YOUR CODE HERE___\":\n",
    "    # Recall that we can use `np.count_nonzero` to count the number of true values in a list, array, or Series\n",
    "    # What might we want to count?\n",
    "    num_true = np.count_nonzero(...)\n",
    "    print(column, num_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we earlier found that there are 51425 items in the dataset. For a lot of these columns, most of the values are null! And for some of them, all of the values are null!\n",
    "\n",
    "Let's drop the columns where there are more than 49000 null values. We can use the `thresh` and `axis` arguments here... What might we need to pass in?\n",
    "\n",
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT\n",
    "cleaned_tweets = tweets.dropna(axis=..., thresh=...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Data\n",
    "Now that we have a cleaned dataset, we can start some analysis! Let's start by using `groupby`, which you might recall from last class. Let's start by looking at how people tweeted in a certain language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's just select the `text` and `lang` columns from our dataset, then group by the language:\n",
    "\n",
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT\n",
    "grouped_by_lang = cleaned_tweets[...].groupby(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try aggregating these values; note that we can use the `sort_values` function to sort a DataFrame by a certain column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_by_lang = grouped_by_lang.count().sort_values('text', ascending=False)\n",
    "count_by_lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second-most common language is `und`, which means undefined -- so there is no language set for that user!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the entries in the lang field are bolded, and when you try to access the column, it returns a key error as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_by_lang[\"lang\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because when you `groupby` a certain column, that makes it the `index` in the resulting DataFrame. What does that mean? That means it makes it the row id for each given row, since there's one row for each value in the column you grouped by! If you want to access the field that you have grouped by, you must reset the index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_by_lang_reset_index = count_by_lang.reset_index()\n",
    "count_by_lang_reset_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can access the lang field!\n",
    "\n",
    "As you may have noticed, English is the most common language among all the tweets. \n",
    "\n",
    "## String Manipulation\n",
    "\n",
    "Now, let's try analyzing the contents of the tweets themselves. Pandas has a built in `str` module which we can use to manipulate string data. For more complex string data, you can use [Regular Expressions](https://en.wikipedia.org/wiki/Regular_expression). There are free online interpreters available such as [regex101](https://regex101.com/) which are helpful for testing out regex code. However, we'll focus on the simpler built in Pandas modules.\n",
    "\n",
    "We can use methods such as:\n",
    "- `df[column].str.replace(<old_value>, <new_value>)`\n",
    "    - replace a string value in a series\n",
    "- `df[column].str.contains(<value>)`\n",
    "    - see if a series contains a string or substring\n",
    "- `df[column].str.lower()`\n",
    "    - make strings all lowercase\n",
    "- `df[column].str.upper()`\n",
    "    - make strings all uppercase\n",
    "- `df[column].str.len()`\n",
    "    - calculate the length of a string\n",
    "- `df[column].str.cat()`\n",
    "    - `cat` is short for concatenate, which is like adding 2 strings together. This is helpful for cases such as combining first and last name to make full name.\n",
    "    \n",
    "Note: This code is might output a warning; we can ignore it.\n",
    "\n",
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT\n",
    "cleaned_tweets['text'] = cleaned_tweets['text']._____() # FILL IN THE FUNCTION\n",
    "cleaned_tweets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try taking a look at how many tweets mention the Warriors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(cleaned_tweets['text'].str.contains('warriors'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So 3737 of the tweets in our dataset contain the word \"warriors\"!\n",
    "\n",
    "This might be an interesting analysis to do for a bunch of words! Let's write a function that takes in a word and outputs the number of times that it is in our dataset.\n",
    "\n",
    "\n",
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT\n",
    "def count_word(word):\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try calling our function on a few different words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_word(\"cavs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_word(\"cavaliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_word(\"lebron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_word(\"steph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try calling the function on some words of your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "Let's try taking a look at our data and finding some information out about it!\n",
    "\n",
    "Summary statistics describe some data. Let's take a look at our tweet data and calculate some summary statistics.\n",
    "- `df.describe()`\n",
    "- `df[column].mean()`\n",
    "- `df[column].min()`\n",
    "- `df[column].max()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleaned_tweets.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a little hard to read! All of these numbers are of type `float`, which is why they have the `e+08` and so next to them -- the code is putting them in scientific notation!\n",
    "\n",
    "To make them easier to read, let's convert them to integers. \n",
    "\n",
    "We can use the pandas [astype()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.astype.html) function to convert a column to a different type -- in this case, let's convert all of our columns to `int`s.\n",
    "\n",
    "`df.astype(int)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tweets.describe().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "What do you notice about the data in each of these? What is the maximum number of followers someone has? What is the average number of followers someone has? What is the median number of followers someone has? Why might some of these statistics make sense or not make sense?\n",
    "\n",
    "Specifically, talk about the `retweet_count`, `followers_count`, and `favourites_count` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Now that you've learned Pandas, try analyzing some of `cleaned_tweets` on your own! Take a look at the columns in the dataset and try using them to investigate something about the data you've been given. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
