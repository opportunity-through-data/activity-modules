{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 6, Class 3: Manipulating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll start with a messy dataset. This is the results of the google form that you just filled out, along with some other responses from other OTD members.\n",
    "\n",
    "Keep in mind that the dataset that we are using is what we call *structued data*. The values are stored in columns and rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('responses.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use some of the methods we just learned about to clean this data. In particular, we will handle null values, convert data types, drop duplicates, and perform some string manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Null Values\n",
    "First off, we are going to handle null values in our dataset. We can find the null values in our dataset with the following commands:\n",
    "- `df.isna()`\n",
    "- `df.notna()`\n",
    "\n",
    "You can call it on the entire dataframe, or pass in a particular column. As far as handling the null values, there are a couple ways of doing this:\n",
    "- `fillna(<value>)`\n",
    "- `dropna()`\n",
    "\n",
    "We can fill null values with another value such as 'missing' or 0, or the mean of the data, or something else. Depending on the data, we might want to drop the null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Data Types\n",
    "\n",
    "Say that we have a column called `age`, but the values are being read as strings. If we want to calculate the average or maximum / minimum age, we need the age values as integers. We can do this through type conversion.\n",
    "\n",
    "For example, we can use the pandas [astype()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.astype.html) function to convert our string age column to an integer column.\n",
    "\n",
    "`df['age'].astype(int)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Duplicates\n",
    "\n",
    "If someone filled our our form more than once with the same exact responses, we may want to drop the duplicates. Imagine that you are storing your data in a database where you have to pay for each row that you store - in this case, we don't want to store any duplicate data that we don't need since it'll be a redundant cost.\n",
    "\n",
    "Luckily for us, there is a [pandas function to drop duplicates](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop_duplicates.html). This will drop duplicate rows and return the dataframe.\n",
    "\n",
    "`df.drop_duplicates`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "\n",
    "We have learned about the different ways that summary statistics can be used to help us with our analysis. Let's take a look at our survey data again and calculate some summary statistics.\n",
    "- `df.describe()`\n",
    "- `df[column].mean()`\n",
    "- `df[column].min()`\n",
    "- `df[column].max()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Manipulation\n",
    "\n",
    "Pandas has a built in `str` module which we can use to manipulate string data. For more complex string data, you can use [Regular Expressions](https://en.wikipedia.org/wiki/Regular_expression). There are free online interpreters available such as [regex101](https://regex101.com/) which are helpful for testing out regex code. However, we'll focus on the simpler built in pandas module.\n",
    "\n",
    "We can use methods such as:\n",
    "- `df[column].str.replace()`\n",
    "    - replace a string value in a series\n",
    "- `df[column].str.contains()`\n",
    "    - see if a series contains a string or substring\n",
    "- `df[column].str.lower()`\n",
    "    - make strings all lowercase\n",
    "- `df[column].str.upper()`\n",
    "    - make strings all uppercase\n",
    "- `df[column].str.len()`\n",
    "    - calculate the length of a string\n",
    "- `df[column].str.cat()`\n",
    "    - `cat` is short for concatenate, which is like adding 2 strings together. This is helpful for cases such as combining first and last name to make full name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
